{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QZVLKxqov8KE"
      },
      "source": [
        "0. Data and Libraries"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8hzemCe5v8KH"
      },
      "source": [
        "0.1 Preprocessed Texts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "7GuNHfsjv8KI"
      },
      "outputs": [],
      "source": [
        "from pandas import read_csv\n",
        "df = read_csv(\"/content/EUSpeech_translated_preprocessed.csv\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wUNfXn7sv8KJ"
      },
      "source": [
        "0.2 Libraries (Especially Unsloth Download)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NTa3Dih-v8KJ",
        "outputId": "7b019923-136a-46af-917b-b90e916d2cad"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: bitsandbytes in /usr/local/lib/python3.11/dist-packages (0.45.4)\n",
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.11/dist-packages (1.5.2)\n",
            "Requirement already satisfied: xformers==0.0.29 in /usr/local/lib/python3.11/dist-packages (0.0.29)\n",
            "Requirement already satisfied: peft in /usr/local/lib/python3.11/dist-packages (0.14.0)\n",
            "Requirement already satisfied: trl in /usr/local/lib/python3.11/dist-packages (0.16.0)\n",
            "Requirement already satisfied: triton in /usr/local/lib/python3.11/dist-packages (3.1.0)\n",
            "Requirement already satisfied: cut_cross_entropy in /usr/local/lib/python3.11/dist-packages (25.1.1)\n",
            "Requirement already satisfied: unsloth_zoo in /usr/local/lib/python3.11/dist-packages (2025.3.17)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.11/dist-packages (0.2.0)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.11/dist-packages (5.29.4)\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.11/dist-packages (3.5.0)\n",
            "Requirement already satisfied: huggingface_hub in /usr/local/lib/python3.11/dist-packages (0.29.3)\n",
            "Requirement already satisfied: hf_transfer in /usr/local/lib/python3.11/dist-packages (0.1.9)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets) (3.18.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.0.2)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (18.1.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.11/dist-packages (from datasets) (4.67.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets) (3.5.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2024.12.0,>=2023.1.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2024.12.0,>=2023.1.0->datasets) (2024.12.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets) (3.11.14)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from datasets) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets) (6.0.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub) (4.12.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (6.2.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (0.3.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.18.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2025.1.31)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
            "Requirement already satisfied: unsloth in /usr/local/lib/python3.11/dist-packages (2025.3.19)\n"
          ]
        }
      ],
      "source": [
        "#capture\n",
        "import os\n",
        "if \"COLAB_\" not in \"\".join(os.environ.keys()):\n",
        "    !pip install unsloth\n",
        "else:\n",
        "    # Do this only in Colab and Kaggle notebooks! Otherwise use pip install unsloth\n",
        "    !pip install --no-deps bitsandbytes accelerate xformers==0.0.29 peft trl triton\n",
        "    !pip install --no-deps cut_cross_entropy unsloth_zoo\n",
        "    !pip install sentencepiece protobuf datasets huggingface_hub hf_transfer\n",
        "    !pip install --no-deps unsloth"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 811
        },
        "collapsed": true,
        "id": "WpOW3Y3Xv8KL",
        "outputId": "070e87b9-ff47-4006-af50-46caa749df55"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: xformers in /usr/local/lib/python3.11/dist-packages (0.0.29)\n",
            "Collecting xformers\n",
            "  Downloading xformers-0.0.29.post3-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (1.0 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from xformers) (2.0.2)\n",
            "Requirement already satisfied: torch==2.6.0 in /usr/local/lib/python3.11/dist-packages (from xformers) (2.6.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->xformers) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->xformers) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->xformers) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->xformers) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->xformers) (2024.12.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->xformers) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->xformers) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->xformers) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->xformers) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->xformers) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->xformers) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->xformers) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->xformers) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->xformers) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->xformers) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->xformers) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->xformers) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->xformers) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->xformers) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->xformers) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch==2.6.0->xformers) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch==2.6.0->xformers) (3.0.2)\n",
            "Downloading xformers-0.0.29.post3-cp311-cp311-manylinux_2_28_x86_64.whl (43.4 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m43.4/43.4 MB\u001b[0m \u001b[31m14.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: xformers\n",
            "  Attempting uninstall: xformers\n",
            "    Found existing installation: xformers 0.0.29\n",
            "    Uninstalling xformers-0.0.29:\n",
            "      Successfully uninstalled xformers-0.0.29\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "unsloth 2025.3.19 requires tyro, which is not installed.\n",
            "unsloth 2025.3.19 requires protobuf<4.0.0, but you have protobuf 5.29.4 which is incompatible.\n",
            "unsloth 2025.3.19 requires trl!=0.15.0,!=0.9.0,!=0.9.1,!=0.9.2,!=0.9.3,<=0.15.2,>=0.7.9, but you have trl 0.16.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed xformers-0.0.29.post3\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "xformers"
                ]
              },
              "id": "ca59c3b106ad451b985965ff3d13c734"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "!pip install --upgrade xformers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AuH8L4Xbv8KL"
      },
      "source": [
        "1. Initialize Unsloth"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade torch torchvision"
      ],
      "metadata": {
        "id": "0pIziyuM1cmo",
        "outputId": "6def270b-23b6-46b2-d61e-9e236bf1d817",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.5.1)\n",
            "Collecting torch\n",
            "  Downloading torch-2.6.0-cp311-cp311-manylinux1_x86_64.whl.metadata (28 kB)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (0.21.0+cu124)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2024.12.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Collecting triton==3.2.0 (from torch)\n",
            "  Downloading triton-3.2.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.4 kB)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torchvision) (2.0.2)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision) (11.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Downloading torch-2.6.0-cp311-cp311-manylinux1_x86_64.whl (766.7 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m766.7/766.7 MB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading triton-3.2.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (253.2 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m253.2/253.2 MB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: triton, torch\n",
            "  Attempting uninstall: triton\n",
            "    Found existing installation: triton 3.1.0\n",
            "    Uninstalling triton-3.1.0:\n",
            "      Successfully uninstalled triton-3.1.0\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 2.5.1\n",
            "    Uninstalling torch-2.5.1:\n",
            "      Successfully uninstalled torch-2.5.1\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "unsloth 2025.3.19 requires tyro, which is not installed.\n",
            "unsloth-zoo 2025.3.17 requires tyro, which is not installed.\n",
            "xformers 0.0.29 requires torch==2.5.1, but you have torch 2.6.0 which is incompatible.\n",
            "unsloth 2025.3.19 requires protobuf<4.0.0, but you have protobuf 5.29.4 which is incompatible.\n",
            "unsloth 2025.3.19 requires trl!=0.15.0,!=0.9.0,!=0.9.1,!=0.9.2,!=0.9.3,<=0.15.2,>=0.7.9, but you have trl 0.16.0 which is incompatible.\n",
            "unsloth-zoo 2025.3.17 requires protobuf<4.0.0, but you have protobuf 5.29.4 which is incompatible.\n",
            "unsloth-zoo 2025.3.17 requires trl!=0.15.0,!=0.9.0,!=0.9.1,!=0.9.2,!=0.9.3,<=0.15.2,>=0.7.9, but you have trl 0.16.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed torch-2.6.0 triton-3.2.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "torch",
                  "torchgen",
                  "triton"
                ]
              },
              "id": "0ae12c5ce25c4cf483660d69c3608a44"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BohSmoPwv8KM",
        "outputId": "26552a2b-adc5-4fb0-cf00-1b927e7090dd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ü¶• Unsloth: Will patch your computer to enable 2x faster free finetuning.\n",
            "ü¶• Unsloth Zoo will now patch everything to make training faster!\n",
            "==((====))==  Unsloth 2025.3.19: Fast Llama patching. Transformers: 4.50.0.\n",
            "   \\\\   /|    Tesla T4. Num GPUs = 1. Max memory: 14.741 GB. Platform: Linux.\n",
            "O^O/ \\_/ \\    Torch: 2.6.0+cu124. CUDA: 7.5. CUDA Toolkit: 12.4. Triton: 3.2.0\n",
            "\\        /    Bfloat16 = FALSE. FA [Xformers = 0.0.29.post3. FA2 = False]\n",
            " \"-____-\"     Free license: http://github.com/unslothai/unsloth\n",
            "Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Unsloth 2025.3.19 patched 28 layers with 28 QKV layers, 28 O layers and 28 MLP layers.\n"
          ]
        }
      ],
      "source": [
        "from unsloth import FastLanguageModel\n",
        "import torch\n",
        "max_seq_length = 2000 # Choose any! We auto support RoPE Scaling internally!\n",
        "dtype = torch.float16 # None for auto detection. Float16 for Tesla T4, V100, Bfloat16 for Ampere+\n",
        "load_in_4bit = False # Use 4bit quantization to reduce memory usage. Can be False.\n",
        "\n",
        "if True:\n",
        "    model, tokenizer = FastLanguageModel.from_pretrained(\n",
        "        model_name = \"lora_model_Llama3.2_3B\", # Pretrained unsloth model\n",
        "        max_seq_length = max_seq_length,\n",
        "        dtype = dtype,\n",
        "        load_in_4bit = load_in_4bit,\n",
        "    )\n",
        "    FastLanguageModel.for_inference(model) # Enable native 2x faster inference"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ktFaNzl5v8KN"
      },
      "source": [
        "2. Test Whether it Works"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LWsxj3Jgv8KN",
        "outputId": "b0fe37b0-05e2-4a56-a597-86761f9d7533"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[\n",
            "  {\n",
            "    \"Solidarity\": \"Solidarity\",\n",
            "    \"Justification\": \"The statement uses the phrase must hold together', which implies unity and cooperation. Additionally, it references 'times of crisis', suggesting that the community is responding to a difficult situation.\"\n",
            "  }\n",
            "]<|eot_id|>\n"
          ]
        }
      ],
      "source": [
        "instruction = (\n",
        "    \"You are an expert political scientist specializing in discourse analysis. \"\n",
        "    \"Your task is to analyze the following statement and determine whether it expresses any indication of solidarity towards another actor. \"\n",
        "    \"For your response, return a JSON array with a single object containing two keys: 'Solidarity' and 'Justification'. \"\n",
        "    \"The 'Solidarity' key should have the value 'Solidarity' if the statement shows support, or 'No Solidarity' if it does not. \"\n",
        "    \"The 'Justification' key should provide a brief explanation (one or two sentences) citing specific phrases or elements that justify your label. \\n\\n\"\n",
        "    \"For example, if the input is:\\n\"\n",
        "    \"\\\"I stand with you in these trying times, offering all my support,\\\" \\n\"\n",
        "    \"then the output should be:\\n\"\n",
        "    \"[\\n\"\n",
        "    \"  {\\n\"\n",
        "    \"    \\\"Solidarity\\\": \\\"Solidarity\\\",\\n\"\n",
        "    \"    \\\"Justification\\\": \\\"The statement explicitly offers support and solidarity through phrases like 'I stand with you' and 'offering all my support'.\\\"\\n\"\n",
        "    \"  }\\n\"\n",
        "    \"]\\n\\n\"\n",
        "    \"If the input is:\\n\"\n",
        "    \"\\\"I am indifferent to your situation,\\\" \\n\"\n",
        "    \"then the output should be:\\n\"\n",
        "    \"[\\n\"\n",
        "    \"  {\\n\"\n",
        "    \"    \\\"Solidarity\\\": \\\"No Solidarity\\\",\\n\"\n",
        "    \"    \\\"Justification\\\": \\\"The statement does not express any form of support or solidarity, as indicated by the word 'indifferent'.\\\"\\n\"\n",
        "    \"  }\\n\"\n",
        "    \"]\\n\\n\"\n",
        "    \"Now, analyze the following text:\\n\"\n",
        ")\n",
        "messages = [\n",
        "    {\"role\": \"system\", \"content\": instruction},\n",
        "    {\"role\": \"user\", \"content\": \"We as a Community of European States must hold together in times of crisis\"}\n",
        "]\n",
        "FastLanguageModel.for_inference(model) # Enable native 2x faster inference\n",
        "inputs = tokenizer.apply_chat_template(\n",
        "    messages,\n",
        "    tokenize = True,\n",
        "    add_generation_prompt = True, # Must add for generation\n",
        "    return_tensors = \"pt\",\n",
        ").to(\"cuda\")\n",
        "\n",
        "from transformers import TextStreamer\n",
        "text_streamer = TextStreamer(tokenizer, skip_prompt = True)\n",
        "_ = model.generate(input_ids = inputs, streamer = text_streamer, max_new_tokens = 300,\n",
        "                   use_cache = True, temperature = 1.0, min_p = 0.1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E_xZFCKov8KO"
      },
      "source": [
        "3. Prompts"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Mk6HkHVv8KP"
      },
      "source": [
        "3.1 Extract Solidarity Sentences"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "_A_aKX9sv8KR"
      },
      "outputs": [],
      "source": [
        "def code_solidarity_label(input_text, model, tokenizer):\n",
        "    \"\"\"\n",
        "    This function instructs the model, an expert political scientist, to analyze a political statement\n",
        "    and decide if it expresses any indication of solidarity towards another actor.\n",
        "    The output is a JSON array with a single object containing two keys:\n",
        "      - \"Solidarity\": \"Solidarity\" if the statement shows explicit support, assistance, or positive alignment towards another party;\n",
        "                        \"No Solidarity\" otherwise.\n",
        "      - \"Justification\": A brief explanation (one or two sentences) justifying the label, referring to specific phrases if applicable.\n",
        "\n",
        "    Parameters:\n",
        "        input_text (str): The text to analyze.\n",
        "        model: The language model.\n",
        "        tokenizer: The tokenizer for the model.\n",
        "\n",
        "    Returns:\n",
        "        str: The model's generated response as a structured JSON array.\n",
        "    \"\"\"\n",
        "\n",
        "    # Define the instruction including examples\n",
        "    instruction = (\n",
        "        \"You are an expert political scientist specializing in discourse analysis. \"\n",
        "        \"Your task is to analyze the following statement and determine whether it expresses any indication of solidarity towards another actor. \"\n",
        "        \"For your response, return a JSON array with a single object containing two keys: 'Solidarity' and 'Justification'. \"\n",
        "        \"The 'Solidarity' key should have the value 'Solidarity' if the statement shows support, or 'No Solidarity' if it does not. \"\n",
        "        \"The 'Justification' key should provide a brief explanation (one or two sentences) citing specific phrases or elements that justify your label. \\n\\n\"\n",
        "        \"For example, if the input is:\\n\"\n",
        "        \"\\\"I stand with you in these trying times, offering all my support,\\\" \\n\"\n",
        "        \"then the output should be:\\n\"\n",
        "        \"[\\n\"\n",
        "        \"  {\\n\"\n",
        "        \"    \\\"Solidarity\\\": \\\"Solidarity\\\",\\n\"\n",
        "        \"    \\\"Justification\\\": \\\"The statement explicitly offers support and solidarity through phrases like 'I stand with you' and 'offering all my support'.\\\"\\n\"\n",
        "        \"  }\\n\"\n",
        "        \"]\\n\\n\"\n",
        "        \"If the input is:\\n\"\n",
        "        \"\\\"I am indifferent to your situation,\\\" \\n\"\n",
        "        \"then the output should be:\\n\"\n",
        "        \"[\\n\"\n",
        "        \"  {\\n\"\n",
        "        \"    \\\"Solidarity\\\": \\\"No Solidarity\\\",\\n\"\n",
        "        \"    \\\"Justification\\\": \\\"The statement does not express any form of support or solidarity, as indicated by the word 'indifferent'.\\\"\\n\"\n",
        "        \"  }\\n\"\n",
        "        \"]\\n\\n\"\n",
        "        \"Now, analyze the following text:\\n\"\n",
        "    )\n",
        "\n",
        "    # Build the prompt\n",
        "    prompt = instruction\n",
        "\n",
        "    # Set up the chat template for the tokenizer (e.g., \"llama-3.1\")\n",
        "    tokenizer = get_chat_template(tokenizer, chat_template=\"llama-3.1\")\n",
        "\n",
        "    # Enable 2x faster inference with FastLanguageModel\n",
        "    FastLanguageModel.for_inference(model)\n",
        "\n",
        "    # Prepare the messages list for chat-style generation.\n",
        "    messages = [\n",
        "        {\"role\": \"system\", \"content\": prompt},\n",
        "        {\"role\": \"user\", \"content\": input_text}\n",
        "    ]\n",
        "\n",
        "    # Apply the chat template to the messages.\n",
        "    inputs = tokenizer.apply_chat_template(\n",
        "        messages,\n",
        "        tokenize=True,\n",
        "        add_generation_prompt=True,  # Must add for generation\n",
        "        return_tensors=\"pt\",\n",
        "    ).to(\"cuda\")\n",
        "\n",
        "    # Generate the output using the model\n",
        "    outputs = model.generate(\n",
        "        input_ids=inputs,\n",
        "        max_new_tokens=512,  # Adjust this value as needed\n",
        "        use_cache=True,\n",
        "        temperature=1.0,\n",
        "        min_p=0.1\n",
        "    )\n",
        "\n",
        "    # Decode the generated tokens\n",
        "    generated_text = tokenizer.batch_decode(outputs)[0].strip()\n",
        "\n",
        "    return generated_text"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xIy4aSd5v8KT"
      },
      "source": [
        "3.2 Extract Solidarity Speech Acts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wEwP_-nIv8KU"
      },
      "outputs": [],
      "source": [
        "def code_solidarity_speech_acts(input_text, model, tokenizer):\n",
        "    \"\"\"\n",
        "    Function that instructs the model to analyze political text and extract solidarity-related speech acts,\n",
        "    returning a structured JSON array with the identified information.\n",
        "\n",
        "    Parameters:\n",
        "        input_text (str): The political text to be analyzed.\n",
        "        model: The language model.\n",
        "        tokenizer: The tokenizer for the model.\n",
        "\n",
        "    Returns:\n",
        "        str: The coded response from the model as a structured JSON array.\n",
        "    \"\"\"\n",
        "\n",
        "    # Optimized instruction for extracting solidarity-related speech acts with structured output\n",
        "    instruction = (\n",
        "        \"You are an expert in political science and computational discourse analysis. \"\n",
        "        \"Your task is to analyze the following political text to identify and code all instances of solidarity-related speech acts. \"\n",
        "        \"A valid solidarity-related speech act must meet these criteria: \"\n",
        "        \"1. Transitive Structure: The utterance must contain a transitive verb structure linking a subject (the provider, typically the speaker) to a direct object (the recipient). \"\n",
        "        \"2. Positive Orientation: The subject expresses a positive orientation (they offer some form of assistance or help, even if verbal) toward the recipient, who is understood to be in a comparatively difficult situation. \"\n",
        "        \"3. Illocutionary Type: The speech act must clearly fall into one of the following categories: \"\n",
        "        \"   - Solidarity Expressives: Utterances that communicate emotional support or compassion without calling for specific action. \"\n",
        "        \"   - Solidarity Directives: Utterances that demand, request, or call on others to act in support of the recipient. \"\n",
        "        \"   - Solidarity Commissives: Utterances in which the speaker commits themselves to take future actions to support the recipient. \"\n",
        "        \"For each solidarity-related speech act identified in the text, extract and return the following information: \"\n",
        "        \"   - SpeechActType: Label the act as 'Expressive,' 'Directive,' or 'Commissive.' \"\n",
        "        \"   - Provider: Identify the actor (usually the speaker) performing the solidarity action. \"\n",
        "        \"   - Recipient: Identify the actor (direct object) who is in need and toward whom the positive orientation is directed. \"\n",
        "        \"   - PropositionalContent: Summarize the core message or demand embedded in the speech act. \"\n",
        "        \"If a sentence does not contain a solidarity-related speech act or lacks the required transitive structure, do not return anything. \"\n",
        "        \"Return your analysis as a structured JSON array where each element represents an identified speech act with the keys \"\n",
        "        \"'SpeechActType,' 'Provider,' 'Recipient,' and 'PropositionalContent.' \"\n",
        "        \"Do not include any additional commentary or text beyond this structured output. \"\n",
        "        \"For example, your output should look like this:\\n\"\n",
        "        \"[\\n\"\n",
        "        \"  {\\n\"\n",
        "        \"    \\\"SpeechActType\\\": \\\"\\\",\\n\"\n",
        "        \"    \\\"Provider\\\": \\\"\\\",\\n\"\n",
        "        \"    \\\"Recipient\\\": \\\"\\\",\\n\"\n",
        "        \"    \\\"PropositionalContent\\\": \\\"\\\"\\n\"\n",
        "        \"  }\\n\"\n",
        "        \"]\\n\"\n",
        "        \"Text to analyze:\\n\"\n",
        "        f\"{input_text}\"\n",
        "    )\n",
        "\n",
        "    # Structuring the message with system and user roles\n",
        "    messages = [\n",
        "        {\"role\": \"user\", \"content\": instruction}\n",
        "    ]\n",
        "\n",
        "    # Creating the text-generation pipeline with a deterministic setting\n",
        "    pipe = pipeline(\"text-generation\", model=model, tokenizer=tokenizer, temperature=0.9)\n",
        "    output = pipe(messages)\n",
        "\n",
        "    # Return the generated response containing the structured JSON analysis\n",
        "    return output[0]['generated_text']\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M2_53lmEv8KW"
      },
      "source": [
        "4. Run the LLM"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "4.1 Pre-Test"
      ],
      "metadata": {
        "id": "Y16TxYa2_XFV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "result = code_solidarity_label(\"I stand with you in these trying times, offering all my support.\", model, tokenizer)\n",
        "print(result)"
      ],
      "metadata": {
        "id": "3HhsCDjMxcw_",
        "outputId": "7e22f7be-5756-4b13-e24e-a86457673a72",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
            "\n",
            "Cutting Knowledge Date: December 2023\n",
            "Today Date: 26 July 2024\n",
            "\n",
            "You are an expert political scientist specializing in discourse analysis. Your task is to analyze the following statement and determine whether it expresses any indication of solidarity towards another actor. For your response, return a JSON array with a single object containing two keys: 'Solidarity' and 'Justification'. The 'Solidarity' key should have the value 'Solidarity' if the statement shows support, or 'No Solidarity' if it does not. The 'Justification' key should provide a brief explanation (one or two sentences) citing specific phrases or elements that justify your label. \n",
            "\n",
            "For example, if the input is:\n",
            "\"I stand with you in these trying times, offering all my support,\" \n",
            "then the output should be:\n",
            "[\n",
            "  {\n",
            "    \"Solidarity\": \"Solidarity\",\n",
            "    \"Justification\": \"The statement explicitly offers support and solidarity through phrases like 'I stand with you' and 'offering all my support'.\"\n",
            "  }\n",
            "]\n",
            "\n",
            "If the input is:\n",
            "\"I am indifferent to your situation,\" \n",
            "then the output should be:\n",
            "[\n",
            "  {\n",
            "    \"Solidarity\": \"No Solidarity\",\n",
            "    \"Justification\": \"The statement does not express any form of support or solidarity, as indicated by the word 'indifferent'.\"\n",
            "  }\n",
            "]\n",
            "\n",
            "Now, analyze the following text:\n",
            "<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
            "\n",
            "I stand with you in these trying times, offering all my support.<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
            "\n",
            "[\n",
            "  {\n",
            "    \"Solidarity\": \"Solidarity\",\n",
            "    \"Justification\": \"The statement explicitly offers support and solidarity through phrases like 'I stand with you' and 'offering all my support'.\"\n",
            "  }\n",
            "]<|eot_id|>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "4.2 JSON Parser"
      ],
      "metadata": {
        "id": "B3AioI3h_aWG"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "QsuYosJNv8KX"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "import re\n",
        "\n",
        "def get_solidarity_label(text, model, tokenizer):\n",
        "    # Call your function that generates the JSON response.\n",
        "    output = code_solidarity_label(text, model, tokenizer)\n",
        "\n",
        "    # Use regex to extract all JSON blocks (non-greedy match)\n",
        "    json_matches = re.findall(r'\\[.*?\\]', output, re.DOTALL)\n",
        "    if json_matches:\n",
        "        # Take the last JSON block, assuming it is the final answer.\n",
        "        json_str = json_matches[-1]\n",
        "    else:\n",
        "        json_str = output  # Fallback if no JSON block is found\n",
        "\n",
        "    try:\n",
        "        data = json.loads(json_str)\n",
        "        if isinstance(data, list) and len(data) > 0:\n",
        "            return data[0]\n",
        "        else:\n",
        "            return {\"Solidarity\": None, \"Justification\": None}\n",
        "    except json.JSONDecodeError:\n",
        "        print(\"JSON decode error for text:\", text)\n",
        "        print(\"Output received:\", output)\n",
        "        return {\"Solidarity\": None, \"Justification\": None}"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "4.3 Run the Function"
      ],
      "metadata": {
        "id": "dUBDs4d3_cMT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import json\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Enable tqdm for pandas\n",
        "tqdm.pandas()\n",
        "\n",
        "# 1. Sample 1000 random rows from the original DataFrame\n",
        "df_sampled = df.sample(n=1000, random_state=42)\n",
        "df_remaining = df.drop(df_sampled.index)\n",
        "\n",
        "# 2. Apply the model function with progress bar\n",
        "results = df_sampled[\"context\"].progress_apply(lambda x: get_solidarity_label(x, model, tokenizer))\n",
        "results_df = pd.DataFrame(results.tolist())\n",
        "\n",
        "# 3. Add the results to the sampled DataFrame\n",
        "df_sampled = df_sampled.reset_index(drop=True)\n",
        "df_sampled = pd.concat([df_sampled, results_df], axis=1)\n",
        "\n",
        "# 4. For remaining rows, fill with \"2\" for both fields\n",
        "df_remaining[\"Solidarity\"] = \"2\"\n",
        "df_remaining[\"Justification\"] = \"2\"\n",
        "\n",
        "# 5. Combine everything back together\n",
        "df_final = pd.concat([df_sampled, df_remaining], axis=0).reset_index(drop=True)\n",
        "\n",
        "# 6. Optional: save to CSV\n",
        "df_final.to_csv(\"solidarity_labels_full.csv\", index=False)\n",
        "\n",
        "# 7. Preview\n",
        "print(df_final.head())\n"
      ],
      "metadata": {
        "id": "G3zXcb4c-tAJ",
        "outputId": "e1cb42b9-de89-44c4-a4be-0fc13e1dc6ce",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 15%|‚ñà‚ñå        | 153/1000 [09:43<1:07:16,  4.77s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "JSON decode error for text: It is very sad, but at the same time symptomatic and I think that will suffice as the entire commentary on the border, the wall, the barrier on the border, but I will also answer partially the questions of the Law and Justice and Confederation MPs. Of course, if we continue to govern, we will maintain the barrier on the border with Belarus. This is both part of our strategy to ensure internal security and part of our commitment to the voters, because about 10.5 million people in the referendum circled \"no\" in Answers to the question: Do you want the wall on the border with Belarus to be dismantled?\n",
            "Output received: <|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
            "\n",
            "Cutting Knowledge Date: December 2023\n",
            "Today Date: 26 July 2024\n",
            "\n",
            "You are an expert political scientist specializing in discourse analysis. Your task is to analyze the following statement and determine whether it expresses any indication of solidarity towards another actor. For your response, return a JSON array with a single object containing two keys: 'Solidarity' and 'Justification'. The 'Solidarity' key should have the value 'Solidarity' if the statement shows support, or 'No Solidarity' if it does not. The 'Justification' key should provide a brief explanation (one or two sentences) citing specific phrases or elements that justify your label. \n",
            "\n",
            "For example, if the input is:\n",
            "\"I stand with you in these trying times, offering all my support,\" \n",
            "then the output should be:\n",
            "[\n",
            "  {\n",
            "    \"Solidarity\": \"Solidarity\",\n",
            "    \"Justification\": \"The statement explicitly offers support and solidarity through phrases like 'I stand with you' and 'offering all my support'.\"\n",
            "  }\n",
            "]\n",
            "\n",
            "If the input is:\n",
            "\"I am indifferent to your situation,\" \n",
            "then the output should be:\n",
            "[\n",
            "  {\n",
            "    \"Solidarity\": \"No Solidarity\",\n",
            "    \"Justification\": \"The statement does not express any form of support or solidarity, as indicated by the word 'indifferent'.\"\n",
            "  }\n",
            "]\n",
            "\n",
            "Now, analyze the following text:\n",
            "<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
            "\n",
            "It is very sad, but at the same time symptomatic and I think that will suffice as the entire commentary on the border, the wall, the barrier on the border, but I will also answer partially the questions of the Law and Justice and Confederation MPs. Of course, if we continue to govern, we will maintain the barrier on the border with Belarus. This is both part of our strategy to ensure internal security and part of our commitment to the voters, because about 10.5 million people in the referendum circled \"no\" in Answers to the question: Do you want the wall on the border with Belarus to be dismantled?<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
            "\n",
            "Here is the output:\n",
            "\n",
            "[\n",
            "  {\n",
            "    \"Solidarity\": \"Solidarity\",\n",
            "    \"Justification\": \"The statement expresses solidarity towards the voters who rejected the idea of dismantling the barrier on the border with Belarus, as indicated by the phrase 'about 10.5 million people in the referendum circled \"no\" in Answers to the question: Do you want the wall on the border with Belarus to be dismantled?\" and the phrase 'part of our commitment to the voters'.\"\n",
            "  }\n",
            "]<|eot_id|>\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 23%|‚ñà‚ñà‚ñé       | 228/1000 [14:44<42:48,  3.33s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "JSON decode error for text: Ukraine's European path was the central theme of my visit to Kyiv. Emmanuel Macron, Klaus Johannis, Mario Draghi and I made it clear in unison: Ukraine belongs to the European family. That is why I will do everything in my power at the European Council tomorrow and the day after to ensure that the entire EU says \"yes\" unanimously: 27 times \"yes\" to candidate status.\n",
            "Output received: <|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
            "\n",
            "Cutting Knowledge Date: December 2023\n",
            "Today Date: 26 July 2024\n",
            "\n",
            "You are an expert political scientist specializing in discourse analysis. Your task is to analyze the following statement and determine whether it expresses any indication of solidarity towards another actor. For your response, return a JSON array with a single object containing two keys: 'Solidarity' and 'Justification'. The 'Solidarity' key should have the value 'Solidarity' if the statement shows support, or 'No Solidarity' if it does not. The 'Justification' key should provide a brief explanation (one or two sentences) citing specific phrases or elements that justify your label. \n",
            "\n",
            "For example, if the input is:\n",
            "\"I stand with you in these trying times, offering all my support,\" \n",
            "then the output should be:\n",
            "[\n",
            "  {\n",
            "    \"Solidarity\": \"Solidarity\",\n",
            "    \"Justification\": \"The statement explicitly offers support and solidarity through phrases like 'I stand with you' and 'offering all my support'.\"\n",
            "  }\n",
            "]\n",
            "\n",
            "If the input is:\n",
            "\"I am indifferent to your situation,\" \n",
            "then the output should be:\n",
            "[\n",
            "  {\n",
            "    \"Solidarity\": \"No Solidarity\",\n",
            "    \"Justification\": \"The statement does not express any form of support or solidarity, as indicated by the word 'indifferent'.\"\n",
            "  }\n",
            "]\n",
            "\n",
            "Now, analyze the following text:\n",
            "<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
            "\n",
            "Ukraine's European path was the central theme of my visit to Kyiv. Emmanuel Macron, Klaus Johannis, Mario Draghi and I made it clear in unison: Ukraine belongs to the European family. That is why I will do everything in my power at the European Council tomorrow and the day after to ensure that the entire EU says \"yes\" unanimously: 27 times \"yes\" to candidate status.<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
            "\n",
            "[\n",
            "  {\n",
            "    \"Solidarity\": \"Solidarity\",\n",
            "    \"Justification\": \"The statement expresses clear support for Ukraine's European path, using phrases like 'Ukraine belongs to the European family' and 'ensure that the entire EU says \"yes\" unanimously'.\"\n",
            "  }\n",
            "]<|eot_id|>\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 642/1000 [40:39<21:55,  3.68s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "JSON decode error for text: But reality, dear colleagues, also includes saying that we have seen Greece unilaterally end the negotiations for the successful conclusion of the second bailout programme after announcing its referendum for next Sunday. We have seen Greece fail to meet its obligation to make payments to the IMF on time. We saw the second aid programme expire at midnight yesterday evening.\n",
            "Output received: <|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
            "\n",
            "Cutting Knowledge Date: December 2023\n",
            "Today Date: 26 July 2024\n",
            "\n",
            "You are an expert political scientist specializing in discourse analysis. Your task is to analyze the following statement and determine whether it expresses any indication of solidarity towards another actor. For your response, return a JSON array with a single object containing two keys: 'Solidarity' and 'Justification'. The 'Solidarity' key should have the value 'Solidarity' if the statement shows support, or 'No Solidarity' if it does not. The 'Justification' key should provide a brief explanation (one or two sentences) citing specific phrases or elements that justify your label. \n",
            "\n",
            "For example, if the input is:\n",
            "\"I stand with you in these trying times, offering all my support,\" \n",
            "then the output should be:\n",
            "[\n",
            "  {\n",
            "    \"Solidarity\": \"Solidarity\",\n",
            "    \"Justification\": \"The statement explicitly offers support and solidarity through phrases like 'I stand with you' and 'offering all my support'.\"\n",
            "  }\n",
            "]\n",
            "\n",
            "If the input is:\n",
            "\"I am indifferent to your situation,\" \n",
            "then the output should be:\n",
            "[\n",
            "  {\n",
            "    \"Solidarity\": \"No Solidarity\",\n",
            "    \"Justification\": \"The statement does not express any form of support or solidarity, as indicated by the word 'indifferent'.\"\n",
            "  }\n",
            "]\n",
            "\n",
            "Now, analyze the following text:\n",
            "<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
            "\n",
            "But reality, dear colleagues, also includes saying that we have seen Greece unilaterally end the negotiations for the successful conclusion of the second bailout programme after announcing its referendum for next Sunday. We have seen Greece fail to meet its obligation to make payments to the IMF on time. We saw the second aid programme expire at midnight yesterday evening.<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
            "\n",
            "[\n",
            "  {\n",
            "    \"Solidarity\": \"No Solidarity\",\n",
            "    \"Justification\": \"The statement does not express any form of support or solidarity, as it describes Greece's actions as negative, such as 'unilaterally ending the negotiations', 'fail[ing] to meet its obligation to make payments', and 'the second aid programme expire[d] at midnight yesterday evening'.\"\n",
            "  }\n",
            "]<|eot_id|>\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 864/1000 [54:44<08:06,  3.57s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "JSON decode error for text: The large European single market, where goods and services, people and capital circulate freely, is intended to be one of the privileged places for the development of electronic commerce. That is why the Member States of the Union will meet in the coming days in Feira in Portugal to adopt the \"e-Europe\" plan, which deploys an ambitious program of common actions, both in the field of training people and in that of opening up the telecommunications sector to competition and supporting innovative companies. To encourage the growth of electronic commerce, Europe is also committed to promoting trust and security on networks.\n",
            "Output received: <|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
            "\n",
            "Cutting Knowledge Date: December 2023\n",
            "Today Date: 26 July 2024\n",
            "\n",
            "You are an expert political scientist specializing in discourse analysis. Your task is to analyze the following statement and determine whether it expresses any indication of solidarity towards another actor. For your response, return a JSON array with a single object containing two keys: 'Solidarity' and 'Justification'. The 'Solidarity' key should have the value 'Solidarity' if the statement shows support, or 'No Solidarity' if it does not. The 'Justification' key should provide a brief explanation (one or two sentences) citing specific phrases or elements that justify your label. \n",
            "\n",
            "For example, if the input is:\n",
            "\"I stand with you in these trying times, offering all my support,\" \n",
            "then the output should be:\n",
            "[\n",
            "  {\n",
            "    \"Solidarity\": \"Solidarity\",\n",
            "    \"Justification\": \"The statement explicitly offers support and solidarity through phrases like 'I stand with you' and 'offering all my support'.\"\n",
            "  }\n",
            "]\n",
            "\n",
            "If the input is:\n",
            "\"I am indifferent to your situation,\" \n",
            "then the output should be:\n",
            "[\n",
            "  {\n",
            "    \"Solidarity\": \"No Solidarity\",\n",
            "    \"Justification\": \"The statement does not express any form of support or solidarity, as indicated by the word 'indifferent'.\"\n",
            "  }\n",
            "]\n",
            "\n",
            "Now, analyze the following text:\n",
            "<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
            "\n",
            "The large European single market, where goods and services, people and capital circulate freely, is intended to be one of the privileged places for the development of electronic commerce. That is why the Member States of the Union will meet in the coming days in Feira in Portugal to adopt the \"e-Europe\" plan, which deploys an ambitious program of common actions, both in the field of training people and in that of opening up the telecommunications sector to competition and supporting innovative companies. To encourage the growth of electronic commerce, Europe is also committed to promoting trust and security on networks.<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
            "\n",
            "[\n",
            "  {\n",
            "    \"Solidarity\": \"Solidarity\",\n",
            "    \"Justification\": \"The statement expresses support for the development of electronic commerce through the adoption of the \"e-Europe\" plan, and mentions the promotion of trust and security on networks as a means to encourage its growth, indicating solidarity towards the Member States of the Union.\"\n",
            "  }\n",
            "]<|eot_id|>\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 947/1000 [59:50<03:35,  4.06s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "JSON decode error for text: This also includes the ability and the will to resolve conflicts peacefully. In this spirit, NATO will continue its so-called \"Intensified Dialogue\" with Ukraine and Georgia. Since 1990, the network of NATO partnerships has been a key chapter in the successes of the \"new\" NATO.\n",
            "Output received: <|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
            "\n",
            "Cutting Knowledge Date: December 2023\n",
            "Today Date: 26 July 2024\n",
            "\n",
            "You are an expert political scientist specializing in discourse analysis. Your task is to analyze the following statement and determine whether it expresses any indication of solidarity towards another actor. For your response, return a JSON array with a single object containing two keys: 'Solidarity' and 'Justification'. The 'Solidarity' key should have the value 'Solidarity' if the statement shows support, or 'No Solidarity' if it does not. The 'Justification' key should provide a brief explanation (one or two sentences) citing specific phrases or elements that justify your label. \n",
            "\n",
            "For example, if the input is:\n",
            "\"I stand with you in these trying times, offering all my support,\" \n",
            "then the output should be:\n",
            "[\n",
            "  {\n",
            "    \"Solidarity\": \"Solidarity\",\n",
            "    \"Justification\": \"The statement explicitly offers support and solidarity through phrases like 'I stand with you' and 'offering all my support'.\"\n",
            "  }\n",
            "]\n",
            "\n",
            "If the input is:\n",
            "\"I am indifferent to your situation,\" \n",
            "then the output should be:\n",
            "[\n",
            "  {\n",
            "    \"Solidarity\": \"No Solidarity\",\n",
            "    \"Justification\": \"The statement does not express any form of support or solidarity, as indicated by the word 'indifferent'.\"\n",
            "  }\n",
            "]\n",
            "\n",
            "Now, analyze the following text:\n",
            "<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
            "\n",
            "This also includes the ability and the will to resolve conflicts peacefully. In this spirit, NATO will continue its so-called \"Intensified Dialogue\" with Ukraine and Georgia. Since 1990, the network of NATO partnerships has been a key chapter in the successes of the \"new\" NATO.<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
            "\n",
            "[\n",
            "  {\n",
            "    \"Solidarity\": \"No Solidarity\",\n",
            "    \"Justification\": \"Although the text mentions NATO's dialogue with Ukraine and Georgia, there is no explicit expression of solidarity or support for the two countries. The phrase'so-called \"Intensified Dialogue\"' implies a somewhat critical tone, and there is no mention of any specific actions or commitments made by NATO in support of Ukraine and Georgia.\"\n",
            "  }\n",
            "]<|eot_id|>\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 990/1000 [1:02:29<00:37,  3.80s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "JSON decode error for text: It has also disrupted supply chains, massively affected the global economy, and made it difficult for children and young people around the world to access education. The brutal war of aggression that Russia is waging against Ukraine is not only causing terrible suffering for the Ukrainian people. It has also led to record prices for grain and fertilizers, oil and gas - with serious consequences, especially in poorer countries.\n",
            "Output received: <|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
            "\n",
            "Cutting Knowledge Date: December 2023\n",
            "Today Date: 26 July 2024\n",
            "\n",
            "You are an expert political scientist specializing in discourse analysis. Your task is to analyze the following statement and determine whether it expresses any indication of solidarity towards another actor. For your response, return a JSON array with a single object containing two keys: 'Solidarity' and 'Justification'. The 'Solidarity' key should have the value 'Solidarity' if the statement shows support, or 'No Solidarity' if it does not. The 'Justification' key should provide a brief explanation (one or two sentences) citing specific phrases or elements that justify your label. \n",
            "\n",
            "For example, if the input is:\n",
            "\"I stand with you in these trying times, offering all my support,\" \n",
            "then the output should be:\n",
            "[\n",
            "  {\n",
            "    \"Solidarity\": \"Solidarity\",\n",
            "    \"Justification\": \"The statement explicitly offers support and solidarity through phrases like 'I stand with you' and 'offering all my support'.\"\n",
            "  }\n",
            "]\n",
            "\n",
            "If the input is:\n",
            "\"I am indifferent to your situation,\" \n",
            "then the output should be:\n",
            "[\n",
            "  {\n",
            "    \"Solidarity\": \"No Solidarity\",\n",
            "    \"Justification\": \"The statement does not express any form of support or solidarity, as indicated by the word 'indifferent'.\"\n",
            "  }\n",
            "]\n",
            "\n",
            "Now, analyze the following text:\n",
            "<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
            "\n",
            "It has also disrupted supply chains, massively affected the global economy, and made it difficult for children and young people around the world to access education. The brutal war of aggression that Russia is waging against Ukraine is not only causing terrible suffering for the Ukrainian people. It has also led to record prices for grain and fertilizers, oil and gas - with serious consequences, especially in poorer countries.<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
            "\n",
            "[\n",
            "  {\n",
            "    \"Solidarity\": \"No Solidarity\",\n",
            "    \"Justification\": \"The statement does not express support or solidarity towards Ukraine, as it instead describes the conflict as a \"brutal war of aggression\" and mentions the negative consequences of the war on the global economy and access to education.\"\n",
            "  }\n",
            "]<|eot_id|>\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1000/1000 [1:03:13<00:00,  3.79s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                             context     Solidarity  \\\n",
            "0  You are thus part of a tradition of centuries-...  No Solidarity   \n",
            "1  We are often asked whether this is so importan...     Solidarity   \n",
            "2  We also have. We are opening soon, in a few da...  No Solidarity   \n",
            "3  The picnic became a world event. But there was...  No Solidarity   \n",
            "4  So, the entire industry and the entire energy ...  No Solidarity   \n",
            "\n",
            "                                       Justification  \n",
            "0  The statement does not express any form of sup...  \n",
            "1  The statement explicitly states that Ukraine's...  \n",
            "2  The statement does not express any form of sup...  \n",
            "3  The statement does not express any form of sup...  \n",
            "4  There is no indication of solidarity towards a...  \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.7"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}